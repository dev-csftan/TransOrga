{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split and merge image\n",
    "from PIL import Image\n",
    "\n",
    "def split_img(img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    image = image.resize((1024,1024))\n",
    "    sub_imgs =[]\n",
    "    for row in range(3):\n",
    "        for col in range(3):\n",
    "            left = col *256\n",
    "            upper = row *256\n",
    "            right = left +512\n",
    "            lower = upper+512\n",
    "\n",
    "            sub_image =image.crop((left,upper,right,lower))\n",
    "            sub_imgs.append(sub_image)\n",
    "    \n",
    "    return sub_imgs\n",
    "\n",
    "def merge_image(images):\n",
    "    merge_image =Image.new(\"L\",[1024,1024])\n",
    "    new_image_0_0 = images[0].crop((0,0,384,384))\n",
    "    new_image_0_1 = images[1].crop((128,0,384,384))\n",
    "    new_image_0_2 = images[2].crop((128,0,512,384))\n",
    "    new_image_1_0 = images[3].crop((0,128,384,384))\n",
    "    new_image_1_1 = images[4].crop((128,128,384,384))\n",
    "    new_image_1_2 = images[5].crop((128,128,512,384))\n",
    "    new_image_2_0 = images[6].crop((0,128,384,512))\n",
    "    new_image_2_1 = images[7].crop((128,128,384,512))\n",
    "    new_image_2_2 = images[8].crop((128,128,512,512))\n",
    "\n",
    "    merge_image.paste(new_image_0_0,(0,0))\n",
    "    merge_image.paste(new_image_0_1,(384,0))\n",
    "    merge_image.paste(new_image_0_2,(640,0))\n",
    "    merge_image.paste(new_image_1_0,(0,384))\n",
    "    merge_image.paste(new_image_1_1,(384,384))\n",
    "    merge_image.paste(new_image_1_2,(640,384))\n",
    "    merge_image.paste(new_image_2_0,(0,640))\n",
    "    merge_image.paste(new_image_2_1,(384,640))\n",
    "    merge_image.paste(new_image_2_2,(640,640))\n",
    "\n",
    "    return merge_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process operations \n",
    "import cv2 \n",
    "import numpy as np\n",
    "import copy\n",
    "def remove_edge_cells(mask_image):\n",
    "    w,h = mask_image.shape\n",
    "    pruned_mask = copy.deepcopy(mask_image)\n",
    "    remove_list = []\n",
    "    edges = mask_image[0,:],mask_image[w-1,:],mask_image[:,0],mask_image[:,h-1]\n",
    "    for edge in edges:\n",
    "        edge_masks = np.unique(edge)\n",
    "        for edge_mask in edge_masks:\n",
    "            remove_list.append(edge_mask)\n",
    "            pruned_mask[np.where(mask_image==edge_mask)] = 0\n",
    "\n",
    "    return pruned_mask\n",
    "\n",
    "def remove_small_cells(mask_image,area_threshold=10):\n",
    "    w,h = mask_image.shape\n",
    "    pruned_mask = copy.deepcopy(mask_image)\n",
    "    for mask_index in np.unique(mask_image):\n",
    "        # if mask_index == mask_image[330,640]:\n",
    "        #     a = 1\n",
    "        area = np.sum(mask_image == mask_index)\n",
    "        if area < area_threshold:\n",
    "            pruned_mask[np.where(mask_image == mask_index)] = 0\n",
    "\n",
    "\n",
    "    return pruned_mask\n",
    "\n",
    "def remove_concentric_masks(mask_image):\n",
    "    # Convert the mask image to grayscale\n",
    "    cell_values = np.unique(mask_image)\n",
    "    for i in range(1, len(cell_values)):# remove background\n",
    "        mask_one = np.array(mask_image == cell_values[i],dtype=np.uint8)\n",
    "        # mask_one_dilated = cv2.dilate(mask_one, np.ones((5, 5), np.uint8),100)\n",
    "        # xmin, xmax, ymin, ymax = np.min(np.where(mask_one == 1)[0]), np.max(np.where(mask_one == 1)[0]),\\\n",
    "        #     np.min(np.where(mask_one == 1)[1]), np.max(np.where(mask_one == 1)[1]),\n",
    "        contour, _ = cv2.findContours(mask_one, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contour) > 0:\n",
    "            largest_contour = max(contour, key=cv2.contourArea)\n",
    "\n",
    "            mask_image = cv2.drawContours(mask_image, [largest_contour], -1, (int(cell_values[i])), thickness=cv2.FILLED)\n",
    "    return mask_image\n",
    "\n",
    "\n",
    "def post_process(final_mask,img_path):\n",
    "    gray_image = final_mask.convert(\"L\")\n",
    "    image_array = np.array(gray_image)\n",
    "    image = cv2.imread(img_path)\n",
    "    resized_img = cv2.resize(image, (1024,1024))    \n",
    "\n",
    "    _,thresholded_image =cv2.threshold(image_array,0,255,cv2.THRESH_BINARY)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresholded_image, connectivity=8)\n",
    "    \n",
    "    output_image=np.zeros_like(gray_image)\n",
    "\n",
    "    for label in range(1,num_labels):\n",
    "        output_image[labels == label] =label\n",
    "    \n",
    "    pruned_mask =remove_edge_cells(output_image)\n",
    "    pruned_mask_reduce = remove_small_cells(pruned_mask,area_threshold=150)\n",
    "    pruned_mask_reduce = remove_concentric_masks(pruned_mask_reduce)\n",
    "    \n",
    "    cell_mask = np.zeros((pruned_mask.shape[0],pruned_mask.shape[1],3))\n",
    "    cell_num = len(np.unique(pruned_mask_reduce)) - 1\n",
    "    \n",
    "    properties ={}\n",
    "    start_idx = 0\n",
    "    for i in range(1, cell_num+1):\n",
    "        mask_one = np.array(pruned_mask_reduce == np.unique(pruned_mask_reduce)[i],dtype=np.uint8)\n",
    "        try:\n",
    "            #properties['cell %i'%(i+start_idx)] = analyze_cell_properties(mask_one)\n",
    "            #cell_color = (np.random.randint(255),\n",
    "            #                                            np.random.randint(255),\n",
    "            #                                            np.random.randint(255))\n",
    "            cell_color =(0,255,0)\n",
    "            # cell_mask[np.where(mask_one==1)[0],np.where(mask_one==1)[1],:] = (255,0,0)\n",
    "            contours, hierarchy = cv2.findContours(mask_one, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cv2.drawContours(cell_mask, contours, -1, cell_color, 3)\n",
    "\n",
    "            text = str(i+start_idx)\n",
    "            # Define the font properties\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1\n",
    "            font_color = cell_color  # White color (BGR format)\n",
    "            thickness = 3\n",
    "\n",
    "            # Find the size of the text\n",
    "            text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "\n",
    "            # Calculate the position to center the text on the image\n",
    "            text_x = ( np.max(np.where(mask_one==1)[0]) - np.min(np.where(mask_one==1)[0]))//2 + np.min(np.where(mask_one==1)[0])\n",
    "            text_y = ( np.max(np.where(mask_one==1)[1]) - np.min(np.where(mask_one==1)[1]))//2 + np.min(np.where(mask_one==1)[1])\n",
    "\n",
    "            # Add the text to the image\n",
    "            cell_mask = cv2.putText(cell_mask, text, (text_y, text_x), font, font_scale, font_color, thickness)\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "    \n",
    "    cell_mask = cv2.addWeighted(np.array(cell_mask, dtype=np.uint8), 1, resized_img, 1, 0)\n",
    "    pure_mask = np.where(pruned_mask_reduce>0,255,0)\n",
    "    return pure_mask,cell_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 1024\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "#main part\n",
    "from organoiddataset import *\n",

    "from torchvision import utils as vutils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def main(img_path):\n",
    "    INPUT_SIZE=512\n",
    "    input_imgs = split_img(img_path)\n",
    "    \n",
    "    transforms_test = transforms.Compose([\n",
    "        transforms.Resize((INPUT_SIZE,INPUT_SIZE)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_dataset =Organoid(\n",
    "        images =input_imgs,transform =transforms_test\n",
    "    )\n",
    "    test_dataloader =DataLoader(test_dataset, batch_size=1,shuffle=False,num_workers=1)\n",
    "\n",
    "    best_model = torch.load('checkpoint.pth', map_location='cpu')\n",
    "\n",
    "    output_imgs = []\n",
    "    for i, (X) in enumerate(test_dataloader):\n",
    "        best_model.eval()\n",
    "        prediction,attention =best_model(X)\n",
    "        output =torch.argmax(prediction,dim=1)\n",
    "        #X = X[0,1,:,:].reshape(1,512,512)\n",
    "        print(output.shape)\n",
    "        #exit()\n",
    "        tensor_to_image =transforms.ToPILImage()\n",
    "        output_img = tensor_to_image(output.to(torch.float32))\n",
    "        output_imgs.append(output_img)\n",
    "    second_mask = merge_image(output_imgs)\n",
    "    final_output,final_mask = post_process(second_mask,img_path)\n",
    "    \n",
    "    return final_output,final_mask\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    target_img_path = \"B03_1.png\"\n",
    "\n",
    "    target_img = Image.open(target_img_path)\n",
    "    width, height = target_img.size\n",
    "    #print(width,height)\n",
    "    final_ouput, final_mask = main(target_img_path)\n",
    "    final_ouput = cv2.resize(final_ouput,(width,height))\n",
    "    final_mask = cv2.resize(final_mask,(width,height))\n",
    "    cv2.imwrite(\"final_output.png\",final_ouput)\n",
    "    cv2.imwrite(\"final_mask.png\",final_mask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('organoid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3dd4b12abbd53ed8e5de8372da2a9e02836e48c92c4a40cf7e855484a750246"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
